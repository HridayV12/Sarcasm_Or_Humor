{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    BertTokenizer, BertModel,\n",
    "    RobertaTokenizer, RobertaModel,\n",
    "    DistilBertTokenizer, DistilBertModel,\n",
    "    XLNetTokenizer, XLNetModel\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and prepare dataset\n",
    "df = pd.read_csv(\"labels.csv\")\n",
    "df['label'] = ((df['humour'] != 'not_funny') | (df['sarcasm'] != 'not_sarcastic')).astype(int)\n",
    "df = df[['text_corrected', 'label']].dropna()\n",
    "\n",
    "# Define constants\n",
    "MAX_LEN = 80\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Tokenizers\n",
    "tokenizers = {\n",
    "    'bert': BertTokenizer.from_pretrained('bert-base-uncased'),\n",
    "    'roberta': RobertaTokenizer.from_pretrained('roberta-base'),\n",
    "    'distilbert': DistilBertTokenizer.from_pretrained('distilbert-base-uncased'),\n",
    "    'xlnet': XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "}\n",
    "\n",
    "# Tokenization helper\n",
    "def tokenize_text(text, tokenizer):\n",
    "    return tokenizer(text, padding=\"max_length\", truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "\n",
    "# Custom Dataset\n",
    "class SarcasmHumorDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizers):\n",
    "        self.texts = texts\n",
    "        self.labels = labels.values\n",
    "        self.tokenizers = tokenizers\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = {model: tokenize_text(text, tokenizer) for model, tokenizer in self.tokenizers.items()}\n",
    "\n",
    "        return {\n",
    "            'bert_input_ids': encoding['bert']['input_ids'].squeeze(0),\n",
    "            'bert_attention_mask': encoding['bert']['attention_mask'].squeeze(0),\n",
    "            'roberta_input_ids': encoding['roberta']['input_ids'].squeeze(0),\n",
    "            'roberta_attention_mask': encoding['roberta']['attention_mask'].squeeze(0),\n",
    "            'distilbert_input_ids': encoding['distilbert']['input_ids'].squeeze(0),\n",
    "            'distilbert_attention_mask': encoding['distilbert']['attention_mask'].squeeze(0),\n",
    "            'xlnet_input_ids': encoding['xlnet']['input_ids'].squeeze(0),\n",
    "            'xlnet_attention_mask': encoding['xlnet']['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "# Model class\n",
    "class BaseClassifier(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(BaseClassifier, self).__init__()\n",
    "        self.model_name = model_name\n",
    "\n",
    "        if model_name == 'bert':\n",
    "            self.encoder = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        elif model_name == 'roberta':\n",
    "            self.encoder = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "        elif model_name == 'distilbert':\n",
    "            self.encoder = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        elif model_name == 'xlnet':\n",
    "            self.encoder = XLNetModel.from_pretrained(\"xlnet-base-cased\")\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        if self.model_name == 'xlnet':\n",
    "            cls_output = outputs.last_hidden_state[:, -1, :]\n",
    "        else:\n",
    "            cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        return self.classifier(self.dropout(cls_output))\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, data_loader, tokenizer_key):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch[f\"{tokenizer_key}_input_ids\"].to(device)\n",
    "            attention_mask = batch[f\"{tokenizer_key}_attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"{tokenizer_key.upper()} Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Split data\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"text_corrected\"], df[\"label\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create loaders\n",
    "train_dataset = SarcasmHumorDataset(train_texts, train_labels, tokenizers)\n",
    "val_dataset = SarcasmHumorDataset(val_texts, val_labels, tokenizers)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Run individual training & evaluation\n",
    "for model_name in ['bert', 'roberta', 'distilbert', 'xlnet']:\n",
    "    print(f\"\\nðŸ” Evaluating {model_name.upper()}...\")\n",
    "\n",
    "    model = BaseClassifier(model_name).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[f\"{model_name}_input_ids\"].to(device)\n",
    "        attention_mask = batch[f\"{model_name}_attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate\n",
    "    evaluate_model(model, val_loader, model_name)\n",
    " \n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    BertTokenizer, BertModel,\n",
    "    RobertaTokenizer, RobertaModel,\n",
    "    DistilBertTokenizer, DistilBertModel,\n",
    "    XLNetTokenizer, XLNetModel\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#  Load dataset\n",
    "df = pd.read_csv(\"labels.csv\")\n",
    "\n",
    "#  Encode labels: 0 = not funny + not sarcastic, 1 = all other combinations\n",
    "df['label'] = ((df['humour'] != 'not_funny') | (df['sarcasm'] != 'not_sarcastic')).astype(int)\n",
    "\n",
    "# Drop unused columns\n",
    "df = df[['text_corrected', 'label']].dropna()\n",
    "\n",
    "#  Define tokenizers\n",
    "tokenizers = {\n",
    "    'bert': BertTokenizer.from_pretrained('bert-base-uncased'),\n",
    "    'roberta': RobertaTokenizer.from_pretrained('roberta-base'),\n",
    "    'distilbert': DistilBertTokenizer.from_pretrained('distilbert-base-uncased'),\n",
    "    'xlnet': XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "}\n",
    "\n",
    "MAX_LEN = 80  # Reduced input size\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize_text(text, tokenizer):\n",
    "    return tokenizer(text, padding=\"max_length\", truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "\n",
    "# 5ï¸âƒ£ Split dataset\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"text_corrected\"], df[\"label\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "#  Custom Dataset class\n",
    "class SarcasmHumorDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizers):\n",
    "        self.texts = texts\n",
    "        self.labels = labels.values\n",
    "        self.tokenizers = tokenizers\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = {model: tokenize_text(text, tokenizer) for model, tokenizer in self.tokenizers.items()}\n",
    "\n",
    "        return {\n",
    "            'bert_input_ids': encoding['bert']['input_ids'].squeeze(0),\n",
    "            'bert_attention_mask': encoding['bert']['attention_mask'].squeeze(0),\n",
    "            'roberta_input_ids': encoding['roberta']['input_ids'].squeeze(0),\n",
    "            'roberta_attention_mask': encoding['roberta']['attention_mask'].squeeze(0),\n",
    "            'distilbert_input_ids': encoding['distilbert']['input_ids'].squeeze(0),\n",
    "            'distilbert_attention_mask': encoding['distilbert']['attention_mask'].squeeze(0),\n",
    "            'xlnet_input_ids': encoding['xlnet']['input_ids'].squeeze(0),\n",
    "            'xlnet_attention_mask': encoding['xlnet']['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "# Create dataset & dataloader\n",
    "train_dataset = SarcasmHumorDataset(train_texts, train_labels, tokenizers)\n",
    "val_dataset = SarcasmHumorDataset(val_texts, val_labels, tokenizers)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)  # Reduced batch size\n",
    "val_loader = DataLoader(val_dataset, batch_size=4)\n",
    "\n",
    "#  Define Optimized Ensemble Model\n",
    "class OptimizedEnsembleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OptimizedEnsembleClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.roberta = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "        self.distilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.xlnet = XLNetModel.from_pretrained(\"xlnet-base-cased\")\n",
    "\n",
    "        # Freeze all model layers\n",
    "        for model in [self.bert, self.roberta, self.distilbert, self.xlnet]:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # Unfreeze last layer only\n",
    "        for model in [self.bert, self.roberta, self.distilbert, self.xlnet]:\n",
    "            for param in list(model.parameters())[-1:]:\n",
    "                param.requires_grad = True\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(4 * 768, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, bert_inputs, roberta_inputs, distilbert_inputs, xlnet_inputs):\n",
    "        bert_cls = self.bert(**bert_inputs).last_hidden_state[:, 0, :]\n",
    "        roberta_cls = self.roberta(**roberta_inputs).last_hidden_state[:, 0, :]\n",
    "        distilbert_cls = self.distilbert(**distilbert_inputs).last_hidden_state[:, 0, :]\n",
    "        xlnet_cls = self.xlnet(**xlnet_inputs).last_hidden_state[:, 0, :]\n",
    "\n",
    "        combined_features = torch.cat((bert_cls, roberta_cls, distilbert_cls, xlnet_cls), dim=1)\n",
    "        return self.fc(combined_features)\n",
    "\n",
    "#  Training Setup\n",
    "EPOCHS = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = OptimizedEnsembleClassifier().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "#  Training Loop (1 epoch)\n",
    "model.train()\n",
    "total_loss, correct = 0, 0\n",
    "\n",
    "for batch in train_loader:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    inputs = {\n",
    "        \"bert_inputs\": {\"input_ids\": batch[\"bert_input_ids\"].to(device), \"attention_mask\": batch[\"bert_attention_mask\"].to(device)},\n",
    "        \"roberta_inputs\": {\"input_ids\": batch[\"roberta_input_ids\"].to(device), \"attention_mask\": batch[\"roberta_attention_mask\"].to(device)},\n",
    "        \"distilbert_inputs\": {\"input_ids\": batch[\"distilbert_input_ids\"].to(device), \"attention_mask\": batch[\"distilbert_attention_mask\"].to(device)},\n",
    "        \"xlnet_inputs\": {\"input_ids\": batch[\"xlnet_input_ids\"].to(device), \"attention_mask\": batch[\"xlnet_attention_mask\"].to(device)}\n",
    "    }\n",
    "\n",
    "    labels = batch[\"label\"].to(device)\n",
    "    outputs = model(**inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "print(f\"Training Loss: {total_loss/len(train_loader):.4f} - Training Accuracy: {correct/len(train_dataset):.4f}\")\n",
    "\n",
    "#  Save Model\n",
    "torch.save(model.state_dict(), \"optimized_ensemble_model.pth\")\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# ðŸ”¹ Evaluate on Validation Set\n",
    "model.eval()\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        inputs = {\n",
    "        \"bert_inputs\": {\"input_ids\": batch[\"bert_input_ids\"].to(device), \"attention_mask\": batch[\"bert_attention_mask\"].to(device)},\n",
    "        \"roberta_inputs\": {\"input_ids\": batch[\"roberta_input_ids\"].to(device), \"attention_mask\": batch[\"roberta_attention_mask\"].to(device)},\n",
    "        \"distilbert_inputs\": {\"input_ids\": batch[\"distilbert_input_ids\"].to(device), \"attention_mask\": batch[\"distilbert_attention_mask\"].to(device)},\n",
    "        \"xlnet_inputs\": {\"input_ids\": batch[\"xlnet_input_ids\"].to(device), \"attention_mask\": batch[\"xlnet_attention_mask\"].to(device)}\n",
    "    }\n",
    "\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        outputs = model(**inputs)\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "print(f\"Validation Accuracy: {correct/len(val_dataset):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#  1. Load Dataset\n",
    "DATA_DIR = 'images'\n",
    "LABELS_FILE = 'labels.csv'\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(LABELS_FILE)\n",
    "\n",
    "# Fix labeling issue\n",
    "def get_label(row):\n",
    "    if row['humour'] != 'not_funny':\n",
    "        return 1  # Humor\n",
    "    elif row['sarcasm'] != 'not_sarcastic':\n",
    "        return 0  # Sarcasm\n",
    "    else:\n",
    "        return -1  # Ignore if neither\n",
    "\n",
    "df['label'] = df.apply(get_label, axis=1)\n",
    "df = df[df['label'] != -1]  # Remove ambiguous cases\n",
    "\n",
    "# Split data\n",
    "train_data, val_data = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "#  2. Define Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "#  3. Create Custom Dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, data_dir, transform=None):\n",
    "        self.data = data\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img_path = os.path.join(self.data_dir, row['image_name'])\n",
    "        label = row['label']\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "#  4. Create Dataloaders with Class Balancing\n",
    "train_dataset = ImageDataset(train_data, DATA_DIR, transform)\n",
    "val_dataset = ImageDataset(val_data, DATA_DIR, transform)\n",
    "\n",
    "# Handle class imbalance using WeightedRandomSampler\n",
    "class_counts = train_data['label'].value_counts().values\n",
    "class_weights = 1. / class_counts\n",
    "samples_weights = [class_weights[label] for label in train_data['label']]\n",
    "sampler = WeightedRandomSampler(samples_weights, num_samples=len(samples_weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, sampler=sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "#  5. Define Ensemble Model\n",
    "class ImageEnsembleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageEnsembleModel, self).__init__()\n",
    "\n",
    "        # Load pretrained models\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.efficientnet = models.efficientnet_b0(pretrained=True)\n",
    "        self.densenet = models.densenet121(pretrained=True)\n",
    "\n",
    "        # Remove last layer and freeze base models\n",
    "        for model in [self.resnet, self.efficientnet, self.densenet]:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        self.efficientnet.classifier[1] = nn.Identity()\n",
    "        self.densenet.classifier = nn.Identity()\n",
    "\n",
    "        # Combined output size = 2048 (ResNet) + 1280 (EfficientNet) + 1024 (DenseNet)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2048 + 1280 + 1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Increased dropout to reduce overfitting\n",
    "            nn.Linear(512, 2)  # 2 classes: sarcasm, humor\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            resnet_out = self.resnet(x)\n",
    "            efficientnet_out = self.efficientnet(x)\n",
    "            densenet_out = self.densenet(x)\n",
    "\n",
    "        combined = torch.cat((resnet_out, efficientnet_out, densenet_out), dim=1)\n",
    "        return self.fc(combined)\n",
    "\n",
    "#  6. Initialize Model and Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ImageEnsembleModel().to(device)\n",
    "\n",
    "# Improved loss function with label smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2)\n",
    "\n",
    "#  7. Train Model\n",
    "EPOCHS = 2\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    scheduler.step(total_loss / len(train_loader))\n",
    "    accuracy = correct / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {total_loss/len(train_loader):.4f} - Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "#  8. Save Model\n",
    "torch.save(model.state_dict(), \"ensemble_image_model.pth\")\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "#  9. Evaluate on Validation Set\n",
    "model.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "val_accuracy = correct / len(val_dataset)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# 10. Prediction Function\n",
    "def predict_image(image_path, model):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        prob = torch.softmax(output, dim=1)[0]\n",
    "\n",
    "        # Adjust threshold to avoid humor bias\n",
    "        if prob[1] > 0.6:\n",
    "            return \"Humor\"\n",
    "        else:\n",
    "            return \"Sarcasm\"\n",
    "\n",
    "# 11. Test Prediction\n",
    "test_image_path = \"test_image.jpg\"\n",
    "result = predict_image(test_image_path, model)\n",
    "print(f\"Prediction: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6987/6987 [1:06:56<00:00,  1.74it/s]\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "import torch\n",
    "from transformers import (\n",
    "    BertTokenizer, BertModel,\n",
    "    RobertaTokenizer, RobertaModel,\n",
    "    DistilBertTokenizer, DistilBertModel,\n",
    "    XLNetTokenizer, XLNetModel\n",
    ")\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"labels.csv\")\n",
    "df = df[['image_name', 'text_corrected']].dropna()\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs(\"text_features\", exist_ok=True)\n",
    "\n",
    "# Load models & tokenizers\n",
    "models = {\n",
    "    'bert': (BertTokenizer.from_pretrained('bert-base-uncased'), BertModel.from_pretrained('bert-base-uncased')),\n",
    "    'roberta': (RobertaTokenizer.from_pretrained('roberta-base'), RobertaModel.from_pretrained('roberta-base')),\n",
    "    'distilbert': (DistilBertTokenizer.from_pretrained('distilbert-base-uncased'), DistilBertModel.from_pretrained('distilbert-base-uncased')),\n",
    "    'xlnet': (XLNetTokenizer.from_pretrained('xlnet-base-cased'), XLNetModel.from_pretrained('xlnet-base-cased')),\n",
    "}\n",
    "\n",
    "# Move models to device and set to eval\n",
    "for _, (_, model) in models.items():\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "MAX_LEN = 80\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_embeddings(text):\n",
    "    embeddings = {}\n",
    "    for name, (tokenizer, model) in models.items():\n",
    "        tokens = tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "        tokens = {k: v.to(device) for k, v in tokens.items()}\n",
    "        output = model(**tokens)\n",
    "\n",
    "        if name == 'xlnet':\n",
    "            cls = output.last_hidden_state[:, -1, :]  # XLNet uses last token\n",
    "        else:\n",
    "            cls = output.last_hidden_state[:, 0, :]  # Others use [CLS] token\n",
    "\n",
    "        embeddings[name] = cls.squeeze(0).cpu()\n",
    "    return embeddings\n",
    "\n",
    "# Process all entries\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    text = row['text_corrected']\n",
    "    image_name = row['image_name']\n",
    "    features = extract_embeddings(text)\n",
    "\n",
    "    save_path = os.path.join(\"text_features\", f\"{image_name}.pt\")\n",
    "    torch.save(features, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hriday Verma\\Desktop\\Major Project\\myenv310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hriday Verma\\Desktop\\Major Project\\myenv310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\Hriday Verma\\Desktop\\Major Project\\myenv310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\Hriday Verma\\Desktop\\Major Project\\myenv310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 6675/6992 [06:47<00:18, 16.95it/s]c:\\Users\\Hriday Verma\\Desktop\\Major Project\\myenv310\\lib\\site-packages\\PIL\\Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6992/6992 [07:06<00:00, 16.39it/s]\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataframe with image names\n",
    "df = pd.read_csv(\"labels.csv\")\n",
    "image_folder = \"images\"\n",
    "os.makedirs(\"image_features\", exist_ok=True)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Image transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load and modify models\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet.fc = nn.Identity()  # Removing the final classification layer\n",
    "\n",
    "efficientnet = models.efficientnet_b0(pretrained=True)\n",
    "efficientnet.classifier[1] = nn.Identity()  # Removing the final classification layer\n",
    "\n",
    "densenet = models.densenet121(pretrained=True)\n",
    "densenet.classifier = nn.Identity()  # Removing the final classification layer\n",
    "\n",
    "# Move to device and eval mode\n",
    "for model in [resnet, efficientnet, densenet]:\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_image_features(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Extract features from each model\n",
    "    features = {\n",
    "        'resnet': resnet(image_tensor).squeeze(0).cpu(),\n",
    "        'efficientnet': efficientnet(image_tensor).squeeze(0).cpu(),\n",
    "        'densenet': densenet(image_tensor).squeeze(0).cpu()\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Process images and save features\n",
    "for image_name in tqdm(df['image_name'].unique()):\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    try:\n",
    "        features = extract_image_features(image_path)\n",
    "        # Save the extracted features for each model in separate files\n",
    "        torch.save(features, os.path.join(\"image_features\", f\"{image_name}.pt\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {image_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 56.7415 - Train Accuracy: 0.9077\n",
      "Epoch 2/5 - Loss: 54.1012 - Train Accuracy: 0.9095\n",
      "Epoch 3/5 - Loss: 53.4660 - Train Accuracy: 0.9095\n",
      "Epoch 4/5 - Loss: 52.9431 - Train Accuracy: 0.9095\n",
      "Epoch 5/5 - Loss: 51.4623 - Train Accuracy: 0.9095\n",
      "Validation Accuracy: 0.9099\n",
      "Fusion model saved.\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dataset paths\n",
    "TEXT_FEAT_DIR = \"text_features\"\n",
    "IMAGE_FEAT_DIR = \"image_features\"\n",
    "df = pd.read_csv(\"labels.csv\")\n",
    "\n",
    "# Filter valid rows\n",
    "df = df[df['image_name'].apply(lambda x: os.path.exists(os.path.join(TEXT_FEAT_DIR, f\"{x}.pt\")) and\n",
    "                                             os.path.exists(os.path.join(IMAGE_FEAT_DIR, f\"{x}.pt\")))]\n",
    "df['label'] = ((df['humour'] != 'not_funny') | (df['sarcasm'] != 'not_sarcastic')).astype(int)\n",
    "\n",
    "# Split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "# Fusion Dataset\n",
    "class FusionDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_id = row['image_name']\n",
    "        label = row['label']\n",
    "\n",
    "        # Load text features\n",
    "        text_feat = torch.load(os.path.join(TEXT_FEAT_DIR, f\"{image_id}.pt\"))\n",
    "        text_emb = torch.cat([\n",
    "            text_feat['bert'],\n",
    "            text_feat['roberta'],\n",
    "            text_feat['distilbert'],\n",
    "            text_feat['xlnet']\n",
    "        ], dim=0)  # Shape: (4Ã—768,)\n",
    "\n",
    "        # Load image features\n",
    "        img_feat = torch.load(os.path.join(IMAGE_FEAT_DIR, f\"{image_id}.pt\"))\n",
    "        img_emb = torch.cat([\n",
    "            img_feat['resnet'],\n",
    "            img_feat['efficientnet'],\n",
    "            img_feat['densenet']\n",
    "        ], dim=0)  # Shape: (2048+1280+1024,)\n",
    "\n",
    "        fused = torch.cat([text_emb, img_emb], dim=0)\n",
    "        return fused, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Dataloaders\n",
    "train_dataset = FusionDataset(train_df)\n",
    "val_dataset = FusionDataset(val_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Late Fusion MLP\n",
    "class LateFusionClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=7424):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Train setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LateFusionClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    for feats, labels in train_loader:\n",
    "        feats, labels = feats.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(feats)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    acc = correct / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {total_loss:.4f} - Train Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for feats, labels in val_loader:\n",
    "        feats, labels = feats.to(device), labels.to(device)\n",
    "        preds = model(feats)\n",
    "        correct += (preds.argmax(1) == labels).sum().item()\n",
    "\n",
    "print(f\"Validation Accuracy: {correct / len(val_dataset):.4f}\") \n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"late_fusion_model.pth\")\n",
    "print(\"Fusion model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 58.1020 - Train Accuracy: 0.9045\n",
      "Epoch 2/5 - Loss: 54.6912 - Train Accuracy: 0.9095\n",
      "Epoch 3/5 - Loss: 54.2749 - Train Accuracy: 0.9095\n",
      "Epoch 4/5 - Loss: 53.5282 - Train Accuracy: 0.9095\n",
      "Epoch 5/5 - Loss: 51.9506 - Train Accuracy: 0.9095\n",
      "Validation Accuracy: 0.9099\n",
      "Fusion model saved.\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Dataset paths\n",
    "TEXT_FEAT_DIR = \"text_features\"\n",
    "IMAGE_FEAT_DIR = \"image_features\"\n",
    "df = pd.read_csv(\"labels.csv\")\n",
    "\n",
    "# Filter valid rows\n",
    "df = df[df['image_name'].apply(lambda x: os.path.exists(os.path.join(TEXT_FEAT_DIR, f\"{x}.pt\")) and\n",
    "                                             os.path.exists(os.path.join(IMAGE_FEAT_DIR, f\"{x}.pt\")))]\n",
    "df['label'] = ((df['humour'] != 'not_funny') | (df['sarcasm'] != 'not_sarcastic')).astype(int)\n",
    "\n",
    "# Split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "# Fusion Dataset\n",
    "class FusionDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_id = row['image_name']\n",
    "        label = row['label']\n",
    "\n",
    "        # Load text features\n",
    "        text_feat = torch.load(os.path.join(TEXT_FEAT_DIR, f\"{image_id}.pt\"))\n",
    "        text_emb = torch.cat([\n",
    "            text_feat['bert'],\n",
    "            text_feat['roberta'],\n",
    "            text_feat['distilbert'],\n",
    "            text_feat['xlnet']\n",
    "        ], dim=0)  # Shape: (4Ã—768,)\n",
    "\n",
    "        # Load image features\n",
    "        img_feat = torch.load(os.path.join(IMAGE_FEAT_DIR, f\"{image_id}.pt\"))\n",
    "        img_emb = torch.cat([\n",
    "            img_feat['resnet'],\n",
    "            img_feat['efficientnet'],\n",
    "            img_feat['densenet']\n",
    "        ], dim=0)  # Shape: (2048+1280+1024,)\n",
    "\n",
    "        fused = torch.cat([text_emb, img_emb], dim=0)\n",
    "        return fused, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Dataloaders\n",
    "train_dataset = FusionDataset(train_df)\n",
    "val_dataset = FusionDataset(val_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Late Fusion MLP\n",
    "class LateFusionClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=7424):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Train setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LateFusionClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    for feats, labels in train_loader:\n",
    "        feats, labels = feats.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(feats)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    acc = correct / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {total_loss:.4f} - Train Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for feats, labels in val_loader:\n",
    "        feats, labels = feats.to(device), labels.to(device)\n",
    "        preds = model(feats)\n",
    "        correct += (preds.argmax(1) == labels).sum().item()\n",
    "\n",
    "print(f\"Validation Accuracy: {correct / len(val_dataset):.4f}\")\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"late_fusion_model.pth\")\n",
    "print(\"Fusion model saved.\")\n",
    "\n",
    "# Function to perform late fusion prediction\n",
    "def late_fusion_predict(image_input=None, text_input=None):\n",
    "    image_features = None\n",
    "    text_features = None\n",
    "\n",
    "    if image_input is not None:\n",
    "        # Extract image features dynamically from the uploaded image\n",
    "        image_features = extract_image_features(image_input)  # You need this function to extract features\n",
    "\n",
    "        # For text, use a dummy empty tensor if no text is provided\n",
    "        text_features = torch.zeros(3072)  # Set to correct size for text features (3072 is 4 * 768)\n",
    "\n",
    "    elif text_input:\n",
    "        # Assuming `TEXT_FEAT_DIR` path and loading text features dynamically\n",
    "        text_feat = torch.load(os.path.join(\"text_features\", f\"{text_input}.pt\"))\n",
    "        text_emb = torch.cat([\n",
    "            text_feat['bert'],\n",
    "            text_feat['roberta'],\n",
    "            text_feat['distilbert'],\n",
    "            text_feat['xlnet']\n",
    "        ], dim=0)\n",
    "        text_features = text_emb\n",
    "\n",
    "        # For image, use a dummy empty tensor if no image is provided\n",
    "        image_features = torch.zeros(4352)  # Set to correct size for image features (2048+1280+1024)\n",
    "\n",
    "    # Combine image and text features\n",
    "    if image_features is not None and text_features is not None:\n",
    "        # Concatenate the image and text features\n",
    "        fused = torch.cat([text_features, image_features], dim=0).unsqueeze(0).to(device)\n",
    "\n",
    "        # Ensure the size is correct for the model input\n",
    "        assert fused.shape[1] == 7424, f\"Expected feature size of 7424, got {fused.shape[1]}\"\n",
    "\n",
    "        # Predict with the model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(fused)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            predicted_class = torch.argmax(probs, dim=1).item()\n",
    "            return predicted_class, probs\n",
    "    else:\n",
    "        return None, None  # If neither image nor text is provided\n",
    "\n",
    "# Function to extract image features (you'll need to define this based on your use case)\n",
    "def extract_image_features(image_input):\n",
    "    # Placeholder function to extract image features\n",
    "    # You'll need to pass the image through the relevant models like ResNet or EfficientNet\n",
    "    # and return a tensor of shape (4352,) (2048+1280+1024)\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
